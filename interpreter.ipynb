{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff78a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Any, Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b06783",
   "metadata": {},
   "source": [
    "## Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec434a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "TokenSpec = [\n",
    "    (\"NUMBER\",      r\"\\d+\"),\n",
    "    (\"NOTE\",        r\"[A-G](?:#|b)?\\d\"),        # e.g., C4, F#3, Bb5\n",
    "    (\"DURATION\",    r\"whole|half|quarter|eighth|sixteenth\"), # common durations\n",
    "    (\"SET\",         r\"Set\\b|set\\b\"),\n",
    "    (\"KEY\",         r\"key\\b|Key\\b\"),\n",
    "    (\"TIME\",        r\"time\\b|Time\\b\"),\n",
    "    (\"SIGNATURE\",   r\"signature\\b|Signature\\b\"),\n",
    "    (\"IN\",          r\"In\\b|in\\b\"),\n",
    "    (\"MEASURE\",     r\"measure\\b|Measure\\b\"),\n",
    "    (\"TO\",          r\"to\\b|To\\b\"),\n",
    "    (\"COLON\",       r\":\"),\n",
    "    (\"COMMA\",       r\",\"),\n",
    "    (\"SLASH\",       r\"/\"),\n",
    "    (\"IDENT\",       r\"[A-Za-z+#]+\"),            # words like 'C', 'major', 'minor'\n",
    "    (\"NEWLINE\",     r\"\\n\"),\n",
    "    (\"WS\",          r\"[ \\t]+\"),\n",
    "    (\"UNKNOWN\",     r\".\"),\n",
    "]\n",
    "tok_regex = \"|\".join(f\"(?P<{name}>{pattern})\" for name, pattern in TokenSpec)\n",
    "\n",
    "@dataclass\n",
    "class Token:\n",
    "    type: str\n",
    "    value: str\n",
    "    pos: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7326c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    def __init__(self, text: str):\n",
    "        self.text = text\n",
    "        self.pos = 0\n",
    "        self.tokens: List[Token] = []\n",
    "\n",
    "    def tokenize(self) -> List[Token]:\n",
    "        for m in re.finditer(tok_regex, self.text):\n",
    "            kind = m.lastgroup\n",
    "            value = m.group()\n",
    "            pos = m.start()\n",
    "            if kind == \"WS\" or kind == \"NEWLINE\":\n",
    "                continue\n",
    "            if kind == \"UNKNOWN\":\n",
    "                raise SyntaxError(f\"Unknown token {value!r} at pos {pos}\")\n",
    " \n",
    "            tok = Token(kind, value, pos)\n",
    "            self.tokens.append(tok)\n",
    "        self.tokens.append(Token(\"EOF\", \"\", len(self.text)))\n",
    "        return self.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fafe0b",
   "metadata": {},
   "source": [
    "### Testing tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22284935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='SET', value='Set', pos=5)\n",
      "Token(type='KEY', value='key', pos=9)\n",
      "Token(type='TO', value='to', pos=13)\n",
      "Token(type='IDENT', value='C', pos=16)\n",
      "Token(type='IDENT', value='major', pos=18)\n",
      "Token(type='SET', value='Set', pos=28)\n",
      "Token(type='TIME', value='time', pos=32)\n",
      "Token(type='SIGNATURE', value='signature', pos=37)\n",
      "Token(type='TO', value='to', pos=47)\n",
      "Token(type='NUMBER', value='4', pos=50)\n",
      "Token(type='SLASH', value='/', pos=51)\n",
      "Token(type='NUMBER', value='4', pos=52)\n",
      "Token(type='IN', value='In', pos=59)\n",
      "Token(type='MEASURE', value='measure', pos=62)\n",
      "Token(type='NUMBER', value='1', pos=70)\n",
      "Token(type='COLON', value=':', pos=71)\n",
      "Token(type='NOTE', value='C4', pos=81)\n",
      "Token(type='DURATION', value='quarter', pos=84)\n",
      "Token(type='COMMA', value=',', pos=91)\n",
      "Token(type='NOTE', value='E4', pos=93)\n",
      "Token(type='DURATION', value='quarter', pos=96)\n",
      "Token(type='COMMA', value=',', pos=103)\n",
      "Token(type='NOTE', value='G4', pos=105)\n",
      "Token(type='DURATION', value='half', pos=108)\n",
      "Token(type='IN', value='In', pos=118)\n",
      "Token(type='MEASURE', value='measure', pos=121)\n",
      "Token(type='NUMBER', value='2', pos=129)\n",
      "Token(type='COLON', value=':', pos=130)\n",
      "Token(type='NOTE', value='F4', pos=140)\n",
      "Token(type='DURATION', value='quarter', pos=143)\n",
      "Token(type='COMMA', value=',', pos=150)\n",
      "Token(type='NOTE', value='A4', pos=152)\n",
      "Token(type='DURATION', value='quarter', pos=155)\n",
      "Token(type='COMMA', value=',', pos=162)\n",
      "Token(type='NOTE', value='C5', pos=164)\n",
      "Token(type='DURATION', value='half', pos=167)\n",
      "Token(type='EOF', value='', pos=176)\n"
     ]
    }
   ],
   "source": [
    "sample = \"\"\"\n",
    "    Set key to C major\n",
    "    Set time signature to 4/4\n",
    "\n",
    "    In measure 1:\n",
    "        C4 quarter, E4 quarter, G4 half\n",
    "\n",
    "    In measure 2:\n",
    "        F4 quarter, A4 quarter, C5 half\n",
    "    \"\"\"\n",
    "lexer = Lexer(sample)\n",
    "tokens = lexer.tokenize()\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
